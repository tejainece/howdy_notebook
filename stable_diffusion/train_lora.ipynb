{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1b15113b-35ff-4ce3-ab4f-d8e1e10958ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxformers\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdiffusers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloaders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AttnProcsLayers\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'datasets'"
     ]
    }
   ],
   "source": [
    "from diffusers import AutoencoderKL, DDPMScheduler, DiffusionPipeline, UNet2DConditionModel\n",
    "from transformers import CLIPTextModel, CLIPTokenizer\n",
    "import torch\n",
    "from diffusers.models.attention_processor import LoRAAttnProcessor\n",
    "import xformers\n",
    "from diffusers.loaders import AttnProcsLayers\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "faf44b40-49e9-422f-8ea3-00183b87036a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='runwayml/stable-diffusion-v1-5'\n",
    "train_data_dir=''\n",
    "rank=4\n",
    "optimizer_cls = torch.optim.AdamW\n",
    "learning_rate=1e-4\n",
    "adam_beta1=0.9\n",
    "adam_beta2=0.999\n",
    "adam_weight_decay=1e-2\n",
    "adam_epsilon=1e-08\n",
    "image_column_name='image'\n",
    "text_column_name='text'\n",
    "# TODO scaling LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fab3e538-af16-4ee5-b361-f0b168469e0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1817152f0b8d4265ae4b713e0232a0c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)tokenizer/vocab.json:   0%|          | 0.00/1.06M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27f3d11f13f941868fb6fa4a4de4f725",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)tokenizer/merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a4c3787a03b490f94bbd2c5697ad523",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/472 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "580ba8bb0eaa40cc8f8ce9c619ed5140",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/806 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe0e82534f444adb961a152db3a2de20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)_encoder/config.json:   0%|          | 0.00/617 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eec3dea3a63b451b81d144d7aad0c718",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/492M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1649b8db64864e03b9da9ad914854e18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)main/vae/config.json:   0%|          | 0.00/547 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "420f075e74084b7eab84bf7e056b43d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ch_model.safetensors:   0%|          | 0.00/335M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d083b6cb44049af8a9cd1511ec8701d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ain/unet/config.json:   0%|          | 0.00/743 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28e8a64103d64341aa05fe6ac9389b55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ch_model.safetensors:   0%|          | 0.00/3.44G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "noise_scheduler = DDPMScheduler.from_pretrained(model_name, subfolder=\"scheduler\")\n",
    "tokenizer = CLIPTokenizer.from_pretrained(model_name, subfolder=\"tokenizer\")\n",
    "text_encoder = CLIPTextModel.from_pretrained(model_name, subfolder=\"text_encoder\")\n",
    "vae = AutoencoderKL.from_pretrained(model_name, subfolder=\"vae\")\n",
    "unet = UNet2DConditionModel.from_pretrained(model_name, subfolder=\"unet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "83ac647f-768d-45e2-ad6d-a8d63391e64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze parameters of models to save more memory\n",
    "unet.requires_grad_(False)\n",
    "vae.requires_grad_(False)\n",
    "text_encoder.requires_grad_(False)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    unet.enable_xformers_memory_efficient_attention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "884dba92-ec7f-4139-be1c-ad88792638d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLIPTextModel(\n",
       "  (text_model): CLIPTextTransformer(\n",
       "    (embeddings): CLIPTextEmbeddings(\n",
       "      (token_embedding): Embedding(49408, 768)\n",
       "      (position_embedding): Embedding(77, 768)\n",
       "    )\n",
       "    (encoder): CLIPEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_dtype = torch.float16\n",
    "device='cpu'\n",
    "# Move unet, vae and text_encoder to device and cast to weight_dtype\n",
    "unet.to(device, dtype=weight_dtype)\n",
    "vae.to(device, dtype=weight_dtype)\n",
    "text_encoder.to(device, dtype=weight_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "be4242a1-2ecc-4636-8d8c-8125aa1e6751",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_attn_procs = {}\n",
    "for name in unet.attn_processors.keys():\n",
    "    cross_attention_dim = None if name.endswith(\"attn1.processor\") else unet.config.cross_attention_dim\n",
    "    if name.startswith(\"mid_block\"):\n",
    "        hidden_size = unet.config.block_out_channels[-1]\n",
    "    elif name.startswith(\"up_blocks\"):\n",
    "        block_id = int(name[len(\"up_blocks.\")])\n",
    "        hidden_size = list(reversed(unet.config.block_out_channels))[block_id]\n",
    "    elif name.startswith(\"down_blocks\"):\n",
    "        block_id = int(name[len(\"down_blocks.\")])\n",
    "        hidden_size = unet.config.block_out_channels[block_id]\n",
    "\n",
    "    lora_attn_procs[name] = LoRAAttnProcessor(\n",
    "        hidden_size=hidden_size,\n",
    "        cross_attention_dim=cross_attention_dim,\n",
    "        rank=rank,\n",
    "    )\n",
    "\n",
    "unet.set_attn_processor(lora_attn_procs)\n",
    "lora_layers = AttnProcsLayers(unet.attn_processors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6747f866-cab5-4797-93c2-d36d90336748",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optimizer_cls(\n",
    "    lora_layers.parameters(),\n",
    "    lr=learning_rate,\n",
    "    betas=(adam_beta1, adam_beta2),\n",
    "    weight_decay=adam_weight_decay,\n",
    "    eps=adam_epsilon,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b65fe0c2-0663-4761-a070-8de2303a44b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m(\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimagefolder\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     data_files\u001b[38;5;241m=\u001b[39mtrain_data_dir,\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m#cache_dir=args.cache_dir,\u001b[39;00m\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      6\u001b[0m column_names \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mcolumn_names\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m image_column_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m column_names:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\n",
    "    \"imagefolder\",\n",
    "    data_files=train_data_dir,\n",
    "    #cache_dir=args.cache_dir,\n",
    ")\n",
    "column_names = dataset[\"train\"].column_names\n",
    "if image_column_name not in column_names:\n",
    "    raise f\"Image column {image_column_name} not in {','.join(column_names)}\"\n",
    "if text_column_name not in column_names:\n",
    "    raise f\"Text column {text_column_name} not in {','.join(column_names)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b0428d-f843-4046-8449-139107d55ee7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
