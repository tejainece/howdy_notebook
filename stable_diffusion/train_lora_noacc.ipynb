{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1b15113b-35ff-4ce3-ab4f-d8e1e10958ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import AutoencoderKL, DDPMScheduler, DiffusionPipeline, UNet2DConditionModel\n",
    "from transformers import CLIPTextModel, CLIPTokenizer\n",
    "import torch\n",
    "from diffusers.models.attention_processor import LoRAAttnProcessor\n",
    "import xformers\n",
    "from diffusers.loaders import AttnProcsLayers\n",
    "from datasets import load_dataset\n",
    "from IPython.display import display\n",
    "from torchvision import transforms\n",
    "from diffusers.optimization import get_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "faf44b40-49e9-422f-8ea3-00183b87036a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='runwayml/stable-diffusion-v1-5'\n",
    "train_data_dir='~/Pictures/lora_datasets/potions'\n",
    "output_dir=''\n",
    "rank=4\n",
    "optimizer_cls = torch.optim.AdamW\n",
    "# Initial learning rate (after the potential warmup period) to use\n",
    "learning_rate=1e-4\n",
    "adam_beta1=0.9\n",
    "adam_beta2=0.999\n",
    "adam_weight_decay=1e-2\n",
    "adam_epsilon=1e-08\n",
    "image_column_name='image'\n",
    "text_column_name='text'\n",
    "resolution=512\n",
    "center_crop=True\n",
    "random_flip=False\n",
    "prediction_type=None\n",
    "max_grad_norm=1.0\n",
    "lr_scheduler='constant' #[\"linear\", \"cosine\", \"cosine_with_restarts\", \"polynomial\", \"constant\", \"constant_with_warmup\"]\n",
    "lr_warmup_steps=500\n",
    "# TODO scaling LR\n",
    "\n",
    "# TODO\n",
    "num_train_epochs=100\n",
    "# Batch size (per device) for the training dataloader\n",
    "train_batch_size=16\n",
    "# Number of updates steps to accumulate before performing a backward/update pass\n",
    "gradient_accumulation_steps=1\n",
    "# Total number of training steps to perform.  If provided, overrides num_train_epochs.\n",
    "max_train_steps=num_train_epochs * 1 # TODO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fab3e538-af16-4ee5-b361-f0b168469e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_scheduler = DDPMScheduler.from_pretrained(model_name, subfolder=\"scheduler\")\n",
    "tokenizer = CLIPTokenizer.from_pretrained(model_name, subfolder=\"tokenizer\")\n",
    "text_encoder = CLIPTextModel.from_pretrained(model_name, subfolder=\"text_encoder\")\n",
    "vae = AutoencoderKL.from_pretrained(model_name, subfolder=\"vae\")\n",
    "unet = UNet2DConditionModel.from_pretrained(model_name, subfolder=\"unet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83ac647f-768d-45e2-ad6d-a8d63391e64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze parameters of models to save more memory\n",
    "unet.requires_grad_(False)\n",
    "vae.requires_grad_(False)\n",
    "text_encoder.requires_grad_(False)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    unet.enable_xformers_memory_efficient_attention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "884dba92-ec7f-4139-be1c-ad88792638d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "weight_dtype = torch.float16\n",
    "device='cuda'\n",
    "# Move unet, vae and text_encoder to device and cast to weight_dtype\n",
    "unet.to(device, dtype=weight_dtype)\n",
    "vae.to(device, dtype=weight_dtype)\n",
    "text_encoder.to(device, dtype=weight_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be4242a1-2ecc-4636-8d8c-8125aa1e6751",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_attn_procs = {}\n",
    "for name in unet.attn_processors.keys():\n",
    "    cross_attention_dim = None if name.endswith(\"attn1.processor\") else unet.config.cross_attention_dim\n",
    "    if name.startswith(\"mid_block\"):\n",
    "        hidden_size = unet.config.block_out_channels[-1]\n",
    "    elif name.startswith(\"up_blocks\"):\n",
    "        block_id = int(name[len(\"up_blocks.\")])\n",
    "        hidden_size = list(reversed(unet.config.block_out_channels))[block_id]\n",
    "    elif name.startswith(\"down_blocks\"):\n",
    "        block_id = int(name[len(\"down_blocks.\")])\n",
    "        hidden_size = unet.config.block_out_channels[block_id]\n",
    "\n",
    "    lora_attn_procs[name] = LoRAAttnProcessor(\n",
    "        hidden_size=hidden_size,\n",
    "        cross_attention_dim=cross_attention_dim,\n",
    "        rank=rank,\n",
    "    )\n",
    "\n",
    "unet.set_attn_processor(lora_attn_procs)\n",
    "lora_layers = AttnProcsLayers(unet.attn_processors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6747f866-cab5-4797-93c2-d36d90336748",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optimizer_cls(\n",
    "    lora_layers.parameters(),\n",
    "    lr=learning_rate,\n",
    "    betas=(adam_beta1, adam_beta2),\n",
    "    weight_decay=adam_weight_decay,\n",
    "    eps=adam_epsilon,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b65fe0c2-0663-4761-a070-8de2303a44b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "135da57d98ec4ad3a05e46a9b4c3e31d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\n",
    "    \"imagefolder\",\n",
    "    data_dir=train_data_dir,\n",
    "    #cache_dir=args.cache_dir,\n",
    ")\n",
    "#display(dataset)\n",
    "column_names = dataset[\"train\"].column_names\n",
    "#print(column_names)\n",
    "if image_column_name not in column_names:\n",
    "    raise f\"Image column {image_column_name} not in {','.join(column_names)}\"\n",
    "if text_column_name not in column_names:\n",
    "    raise f\"Text column {text_column_name} not in {','.join(column_names)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1738e647-8fcf-4f9f-87c6-6fb1833ff66f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize(resolution, interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "    transforms.CenterCrop(resolution) if center_crop else transforms.RandomCrop(args.resolution),\n",
    "    transforms.RandomHorizontalFlip() if random_flip else transforms.Lambda(lambda x: x),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5]),\n",
    "])\n",
    "\n",
    "def preprocess_train(items):\n",
    "    display(items)\n",
    "    print('here')\n",
    "    images = [image.convert(\"RGB\") for image in items[image_column]]\n",
    "    items[\"pixel_values\"] = [train_transforms(image) for image in images]\n",
    "    items[\"input_ids\"] = tokenize_captions(examples)\n",
    "    return items\n",
    "\n",
    "train_dataset = dataset[\"train\"].with_transform(preprocess_train)\n",
    "\n",
    "def collate_fn(items):\n",
    "    pixel_values = torch.stack([item[\"pixel_values\"] for item in items])\n",
    "    pixel_values = pixel_values.to(memory_format=torch.contiguous_format).float()\n",
    "    input_ids = torch.stack([item[\"input_ids\"] for item in items])\n",
    "    return {\"pixel_values\": pixel_values, \"input_ids\": input_ids}\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    "    batch_size=train_batch_size,\n",
    "    # num_workers=args.dataloader_num_workers,\n",
    ")\n",
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5ba4d465-a169-4e3a-8bc2-4842a93091a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = get_scheduler(\n",
    "    lr_scheduler,\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=lr_warmup_steps,\n",
    "    num_training_steps=max_train_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cb0f82f2-346d-47e5-97be-cc905d21dd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_epoch=0\n",
    "global_step=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3edc1062-ad91-423e-b986-fc1d311e0dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': [<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=512x512>,\n",
       "  <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=512x512>,\n",
       "  <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=512x512>,\n",
       "  <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=512x512>,\n",
       "  <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=512x512>,\n",
       "  <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=512x512>,\n",
       "  <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=512x512>,\n",
       "  <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=512x512>,\n",
       "  <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=512x512>,\n",
       "  <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=512x512>,\n",
       "  <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=512x512>,\n",
       "  <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=512x512>,\n",
       "  <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=512x512>,\n",
       "  <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=512x512>,\n",
       "  <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=498x512>,\n",
       "  <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=512x512>],\n",
       " 'text': ['a single spherical glass bottle filled with blue magic potion, blue potion, mana potion, gameartpotionbottle, game asset, magical potion, bioluminescent, blue bioluminescent magical potion, single potion bottle, spherical glass bottle, spherical potion bottle, cork potion bottle, wooden cork, rendered art, rendered illustration, concept art, magic item, potion bottle standing straight',\n",
       "  \"a single rectangular glass bottle filled with yellow magic potion, yellow potion, gameartpotionbottle, game asset, magical potion, bioluminescent, bioluminescent magical potion, glowing magical potion, single potion bottle, rectangular glass bottle, rectangular potion bottle, cork potion bottle, wooden cork, rendered art, rendered illustration, concept art, magic item, potion bottle standing straight, top down view of potion bottle, rope around bottle's neck, tag hanging from bottle's neck by a rope\",\n",
       "  'glass bottles filled with magic potion, pink potion, orange potion, yellow potion, green potion, blue potion, purple potion, teal potion, gameartpotionbottle, game asset, glowing magical potion, bioluminescent, bioluminescent magical potion, magical potion, cork potion bottle, wooden cork, rendered art, rendered illustration, concept art, magic item, potion bottle standing straight',\n",
       "  'a single spherical glass bottle filled with orange magic potion, orange potion, gameartpotionbottle, game asset, magical potion, single potion bottle, spherical glass bottle, spherical potion bottle, cork potion bottle, metal cork, rendered illustration, rendered art, concept art, magic item, potion bottle leaning right, potion bottle belt loop',\n",
       "  \"a single spherical glass bottle filled with pink magic potion, pink potion, potion boiling, gameartpotionbottle, game asset, magical potion, single potion bottle, spherical glass bottle, spherical potion bottle, cork potion bottle, wooden cork, rendered art, rendered illustration, concept art, magic item, potion bottle leaning right, rope around bottle's neck, tag hanging from bottle's neck by a rope\",\n",
       "  \"a single spherical glass bottle filled with green magic potion, green potion, gameartpotionbottle, game asset, glowing magical potion, single potion bottle, bioluminescent, bioluminescent magical potion, magical potion, spherical glass bottle, spherical potion bottle, cork potion bottle, wooden cork, rendered art, rendered illustration, concept art, magic item, potion bottle leaning left, rope around bottle's neck\",\n",
       "  \"a single bevelled cirucular glass bottle filled with green magic potion, green potion, gameartpotionbottle, game asset, magical potion, bioluminescent, bioluminescent magical potion, glowing magical potion, single potion bottle, cork potion bottle, wooden cork, rendered art, rendered illustration, concept art, magic item, potion bottle standing straight, rope around bottle's neck, tag hanging from bottle's neck by a rope\",\n",
       "  \"a single heart shaped glass bottle filled with pink magic potion, potion of love, love potion, pink potion, heart shaped potion bottle, bubbles in potion, gameartpotionbottle, game asset, magical potion, bioluminescent, bioluminescent magical potion, glowing magical potion, single potion bottle, heart shaped glass bottle, heart shaped potion bottle, cork potion bottle, wooden cork, rendered art, rendered illustration, concept art, magic item, potion bottle standing straight, tag around bottle's neck\",\n",
       "  'a single spherical glass bottle filled with violet magic potion, violet potion, bubbles in potion, potion boiling, gameartpotionbottle, game asset, magical potion, bioluminescent, bioluminescent magical potion, glowing magical potion, single potion bottle, spherical glass bottle, spherical potion bottle, cork potion bottle, wooden cork, rendered art, rendered illustration, concept art, magic item, potion bottle standing straight',\n",
       "  'a single rectangular glass bottle filled with orange magic potion, orange potion, gameartpotionbottle, game asset, magical potion, bioluminescent, orange bioluminescent magical potion, single potion bottle, rectangular glass bottle, rectangular potion bottle, cork potion bottle, wooden cork, rendered art, rendered illustration, concept art, magic item, potion bottle standing straight',\n",
       "  \"a single rectangular glass bottle filled with violet magic potion, violet potion, gameartpotionbottle, game asset, magical potion, bioluminescent, violet bioluminescent magical potion, single potion bottle, rectangular glass bottle, rectangular potion bottle, cork potion bottle, wooden cork, rendered art, rendered illustration, concept art, magic item, potion bottle leaning right, rope around bottle's neck, tag hanging from bottle's neck by a rope\",\n",
       "  \"a single spherical glass bottle filled with green magic potion, healing potion, potion of healing, green potion, bubbles in potion, rope around bottle's neck, gameartpotionbottle, game asset, glowing magical potion, single potion bottle, bioluminescent, bioluminescent magical potion, magical potion, spherical glass bottle, spherical potion bottle, cork potion bottle, wooden cork, rendered art, rendered illustration, concept art, magic item, potion bottle leaning right, bubbles in potion, bubbles in liquid, tag hanging from bottle's neck by a rope\",\n",
       "  'a single spherical glass bottle filled with green magic potion, healing potion, potion of healing, green potion, gameartpotionbottle, game asset, glowing magical potion, single potion bottle, bioluminescent, bioluminescent magical potion, magical potion, spherical glass bottle, spherical potion bottle, cork potion bottle, wooden cork, rendered art, rendered illustration, concept art, magic item, potion bottle leaning right, potion bottle on metallic bottle holder',\n",
       "  'a single tetrahedron glass bottle filled with green magic potion, healing potion, potion of healing, green potion, gameartpotionbottle, game asset, glowing magical potion, single potion bottle, bioluminescent, bioluminescent magical potion, magical potion, tetrahedron glass bottle, tetrahedron potion bottle, cork potion bottle, wooden cork, rendered art, rendered illustration, concept art, magic item, potion bottle standing straight',\n",
       "  \"a single spherical glass bottle filled with blue magic potion, mana potion, blue potion, rope around bottle's neck, gameartpotionbottle, game asset, glowing magical potion, bioluminescent, bioluminescent magical potion, magical potion, single potion bottle, spherical glass bottle, spherical potion bottle, cork potion bottle, wooden cork, rendered art, rendered illustration, concept art, magic item, potion bottle leaning right\",\n",
       "  'a single spherical glass bottle filled with green magic potion, green potion, gameartpotionbottle, game asset, magical potion, bioluminescent, green bioluminescent magical potion, single potion bottle, spherical glass bottle, spherical potion bottle, cork potion bottle, metal cork, skull shaped metal cork, rendered art, rendered illustration, concept art, magic item, potion bottle standing straight']}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'image_column' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m unet\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      3\u001b[0m train_loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_dataloader):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# TODO skip steps until we reach the resumed step\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# TODO accelerate.accumulate\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# Convert images to latent space\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     latents \u001b[38;5;241m=\u001b[39m vae\u001b[38;5;241m.\u001b[39mencode(batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpixel_values\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(dtype\u001b[38;5;241m=\u001b[39mweight_dtype))\u001b[38;5;241m.\u001b[39mlatent_dist\u001b[38;5;241m.\u001b[39msample()\n\u001b[1;32m     11\u001b[0m     latents \u001b[38;5;241m=\u001b[39m latents \u001b[38;5;241m*\u001b[39m vae\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mscaling_factor\n",
      "File \u001b[0;32m~/projects/howdy_notebook/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/projects/howdy_notebook/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/projects/howdy_notebook/venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[0;32m~/projects/howdy_notebook/venv/lib/python3.11/site-packages/datasets/arrow_dataset.py:2807\u001b[0m, in \u001b[0;36mDataset.__getitems__\u001b[0;34m(self, keys)\u001b[0m\n\u001b[1;32m   2805\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitems__\u001b[39m(\u001b[38;5;28mself\u001b[39m, keys: List) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List:\n\u001b[1;32m   2806\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Can be used to get a batch using a list of integers indices.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2807\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2808\u001b[0m     n_examples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch[\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(batch))])\n\u001b[1;32m   2809\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [{col: array[i] \u001b[38;5;28;01mfor\u001b[39;00m col, array \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems()} \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_examples)]\n",
      "File \u001b[0;32m~/projects/howdy_notebook/venv/lib/python3.11/site-packages/datasets/arrow_dataset.py:2803\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2801\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):  \u001b[38;5;66;03m# noqa: F811\u001b[39;00m\n\u001b[1;32m   2802\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/howdy_notebook/venv/lib/python3.11/site-packages/datasets/arrow_dataset.py:2788\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[0;34m(self, key, **kwargs)\u001b[0m\n\u001b[1;32m   2786\u001b[0m formatter \u001b[38;5;241m=\u001b[39m get_formatter(format_type, features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mfeatures, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mformat_kwargs)\n\u001b[1;32m   2787\u001b[0m pa_subtable \u001b[38;5;241m=\u001b[39m query_table(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data, key, indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indices \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 2788\u001b[0m formatted_output \u001b[38;5;241m=\u001b[39m \u001b[43mformat_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpa_subtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformatter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformat_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformat_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_all_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_all_columns\u001b[49m\n\u001b[1;32m   2790\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2791\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m formatted_output\n",
      "File \u001b[0;32m~/projects/howdy_notebook/venv/lib/python3.11/site-packages/datasets/formatting/formatting.py:629\u001b[0m, in \u001b[0;36mformat_table\u001b[0;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[1;32m    627\u001b[0m python_formatter \u001b[38;5;241m=\u001b[39m PythonFormatter(features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m format_columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 629\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m format_columns:\n",
      "File \u001b[0;32m~/projects/howdy_notebook/venv/lib/python3.11/site-packages/datasets/formatting/formatting.py:400\u001b[0m, in \u001b[0;36mFormatter.__call__\u001b[0;34m(self, pa_table, query_type)\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_column(pa_table)\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 400\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/howdy_notebook/venv/lib/python3.11/site-packages/datasets/formatting/formatting.py:515\u001b[0m, in \u001b[0;36mCustomFormatter.format_batch\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m    513\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_arrow_extractor()\u001b[38;5;241m.\u001b[39mextract_batch(pa_table)\n\u001b[1;32m    514\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_features_decoder\u001b[38;5;241m.\u001b[39mdecode_batch(batch)\n\u001b[0;32m--> 515\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[43], line 12\u001b[0m, in \u001b[0;36mpreprocess_train\u001b[0;34m(items)\u001b[0m\n\u001b[1;32m     10\u001b[0m display(items)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhere\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m images \u001b[38;5;241m=\u001b[39m [image\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m items[\u001b[43mimage_column\u001b[49m]]\n\u001b[1;32m     13\u001b[0m items[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpixel_values\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m [train_transforms(image) \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m images]\n\u001b[1;32m     14\u001b[0m items[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m tokenize_captions(examples)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'image_column' is not defined"
     ]
    }
   ],
   "source": [
    "for epoch in range(first_epoch, num_train_epochs):\n",
    "    unet.train()\n",
    "    train_loss=0.0\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # TODO skip steps until we reach the resumed step\n",
    "\n",
    "        # TODO accelerate.accumulate\n",
    "\n",
    "        # Convert images to latent space\n",
    "        latents = vae.encode(batch[\"pixel_values\"].to(dtype=weight_dtype)).latent_dist.sample()\n",
    "        latents = latents * vae.config.scaling_factor\n",
    "\n",
    "        # Sample noise that we'll add to the latents\n",
    "        noise = torch.randn_like(latents)\n",
    "\n",
    "        bsz = latents.shape[0]\n",
    "        # Sample a random timestep for each image\n",
    "        timesteps = torch.randint(0, noise_scheduler.config.num_train_timesteps, (bsz,), device=latents.device)\n",
    "        timesteps = timesteps.long()\n",
    "\n",
    "        # Add noise to the latents according to the noise magnitude at each timestep\n",
    "        # (this is the forward diffusion process)\n",
    "        noisy_latents = noise_scheduler.add_noise(latents, noise, timesteps)\n",
    "        \n",
    "        # Get the text embedding for conditioning\n",
    "        encoder_hidden_states = text_encoder(batch[\"input_ids\"])[0]\n",
    "\n",
    "        \n",
    "        # Get the target for loss depending on the prediction type\n",
    "        if prediction_type is not None:\n",
    "            # set prediction_type of scheduler if defined\n",
    "            noise_scheduler.register_to_config(prediction_type=prediction_type)\n",
    "\n",
    "        if noise_scheduler.config.prediction_type == \"epsilon\":\n",
    "            target = noise\n",
    "        elif noise_scheduler.config.prediction_type == \"v_prediction\":\n",
    "            target = noise_scheduler.get_velocity(latents, noise, timesteps)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown prediction type {noise_scheduler.config.prediction_type}\")\n",
    "\n",
    "        # Predict the noise residual and compute loss\n",
    "        model_pred = unet(noisy_latents, timesteps, encoder_hidden_states).sample\n",
    "        loss = F.mse_loss(model_pred.float(), target.float(), reduction=\"mean\")\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(lora_layers.parameters, max_norm=max_grad_norm)\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6a183a-a886-4f5a-8b5f-4bff171c8d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = unet.to(torch.float32)\n",
    "unet.save_attn_procs(args.output_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
